# ============================================================
#   íŒŒì¼ëª…: 11_topic_modeling.py
#   ëª©ì : ì‹œê¸°ë³„ LDA í† í”½ ëª¨ë¸ë§ (ê³µì§ì‚¬íšŒ ì¸ì‹ ì£¼ì œ ë„ì¶œ)
# ============================================================

import pandas as pd
from konlpy.tag import Okt
from gensim import corpora, models
import matplotlib.pyplot as plt
from wordcloud import WordCloud
import platform

# ---------- 1. í°íŠ¸ ì„¤ì • ----------
if platform.system() == "Windows":
    font_path = "C:/Windows/Fonts/malgun.ttf"  #  Windowsìš© í•œê¸€ í°íŠ¸
elif platform.system() == "Darwin":
    font_path = "/System/Library/Fonts/AppleSDGothicNeo.ttc"  #  macOS
else:
    font_path = "/usr/share/fonts/truetype/nanum/NanumGothic.ttf"  # Linux

plt.rcParams["axes.unicode_minus"] = False

okt = Okt()

# ------------------------------------------------------------
# ğŸ”¹ ë¶ˆìš©ì–´ ì„¤ì • (ì´ì „ ë‹¨ê³„ ë™ì¼)
# ------------------------------------------------------------
EXCLUDE_WORDS = [
 # ì •ì¹˜ ë° ê¸°ê´€ëª…
    'ì •ë¶€', 'ê³µì§ì', 'ê³µë¬´ì›', 'ì •ì±…', 'êµ­ê°€', 'ì œë„',
    'ìœ„ì›íšŒ', 'ë¶€ì²˜', 'êµ­íšŒ', 'ì¥ê´€', 'ëŒ€í†µë ¹', 'ì²­ì™€ëŒ€', 'ì„œìš¸ì‹œ',
    'ì˜ì›', 'ê¸°ì', 'ìœ„ì›', 'ìœ„ì›ì¥', 'ê´€ê³„ì', 'ë‹¨ì²´', 'ê¸°ê´€', 'ë³¸ë¶€',
    'ë°œí‘œ', 'íšŒì˜', 'ì˜ˆì‚°', 'ì¡°ì‚¬', 'ë³´ê³ ì„œ', 'ì–¸ë¡ ', 'ë‚˜ë¼', 'ì‹œì¥',

    # ì •ì¹˜ì¸ ë° ì •ë‹¹
    'ìœ¤ì„ì—´', 'ìœ¤ì„ë ¬', 'ê¹€ê±´í¬', 'ì´ì¬ëª…', 'ì¡°êµ­', 'ë¬¸ì¬ì¸', 'ë°•ê·¼í˜œ',
    'ì´ëª…ë°•', 'êµ­ë¯¼ì˜í˜', 'ë¯¼ì£¼ë‹¹', 'ë”ë¶ˆì–´ë¯¼ì£¼ë‹¹', 'êµ­í˜', 'í˜ì‹ ë‹¹', 'ë¯¼ì£¼',
    'ì§„ë³´', 'ë³´ìˆ˜', 'ë”ë¶ˆì–´',

    # ì§€ëª… ë° ì§€ì—­
    'í•œêµ­', 'ëŒ€í•œë¯¼êµ­', 'ì„œìš¸', 'ì¼ë³¸', 'ëŒ€ë§Œ', 'ì§€ë°©', 'ê°•ì§„êµ°', 'ì „êµ­', 'ì¸ì²œ',

    # ë¶ˆí•„ìš” ì—°ê²°ì–´ / ê¸°ëŠ¥ì–´
    'ê´€ë ¨', 'í†µí•´', 'ì˜ê²¬', 'ë…¼ì˜', 'ì¶”ì§„', 'ë°©ì•ˆ', 'ì§€ì ',
    'í™•ëŒ€', 'ìš”êµ¬', 'ëŒ€ìƒ', 'ì¤‘ìš”', 'ì‚¬ì‹¤', 'ì…ì¥', 'ì‹œì‘', 'ì²˜ë¦¬','ìœ„í•´', 'ëŒ€í•œ', 'ì´ë²ˆ',

    # ì‚¬ê±´Â·ì‚¬ê³  ë° ë‰´ìŠ¤ìš©ì–´
    'ì‚¬ê±´', 'ì‚¬ì•ˆ', 'í”¼í•´ì', 'ì„±í­ë ¥', 'ì„±í¬ë¡±', 'ë¹„ì„œ', 'ë¹„ì„œì‹¤',
    'íˆ¬í‘œ', 'ì„ ê±°', 'ëŒ€ì„ ', 'íƒ„í•µ', 'ì´›ë¶ˆ', 'ë²•ì•ˆ', 'ê²€ì°°', 'ì‹¬íŒ',

    # ì—­ì‚¬/ì˜ë¡€/êµ­ê°€ë³´í›ˆ
    'ì „ìŸ', 'í˜¸êµ­', 'í˜„ì¶©ì¼', 'ë…ë¦½ìš´ë™', 'ë…ë¦½ìš´ë™ê°€', 'íƒœê·¹ê¸°', 'ìœ ê³µ', 'ë³´í›ˆ', 'í¬ìƒ',

    # ì¼ë°˜ ì‚¬íšŒì–´
    'í•™êµ', 'í•™ìƒ', 'ì•„ì´', 'ìœ ì¹˜ì›', 'ë¶€ëª¨', 'ì¹œêµ¬', 'ê¸‰ì‹',
    'ì¶œì‚°ìœ¨', 'ê°€ì¡±', 'ë…¸ì¸', 'ì£¼íƒ', 'ì§€ì—­', 'ë¶€ë‹´',

    # ê¸°ì‚¬ ì‘ì„±ìš© í‘œí˜„
    'ëŒ€í‘œ', 'ê¸°íš', 'ê¸°ë¶„', 'ê²°ì •', 'ì‚¬ì‹¤', 'ì§€ë‚œë‹¬', 'ì‹œê°„', 'ë‚´ë…„', 'ì‚¬ì •', 'ì„ ì„', 'ë°œìƒ', 'ì‹ ê³ ',

    # ê¸°íƒ€ ë¶ˆí•„ìš” ë‹¨ì–´
    'íš¨ëŠ¥', 'ì—°êµ¬ì›', 'ì—°êµ¬ì†Œ', 'ì‚¬íšŒí•™', 'ë…ì', 'í‰ê°€', 'ëŒ€ì±…', 'ì•…ì„±', 'í”¼í¬', 'ì§€ë‚œí•´', 'ì¸ìƒ', 'ì§€ë‚œ', 'ì¶”ë…', 'ì£¼ëª©', 'ìµœê·¼', 'ì´ìƒ', 'ì‚¬ëŒ', 'ì—¬ë¡ ì¡°ì‚¬'
]

# ------------------------------------------------------------
# ğŸ”¹ ëª…ì‚¬ ì¶”ì¶œ + ì „ì²˜ë¦¬
# ------------------------------------------------------------
def tokenize(text):
    words = okt.nouns(str(text))
    return [w for w in words if len(w) > 1 and w not in EXCLUDE_WORDS]

# ------------------------------------------------------------
# ğŸ”¹ LDA í† í”½ ëª¨ë¸ë§ í•¨ìˆ˜
# ------------------------------------------------------------
def lda_topic_modeling(file_path, title, num_topics=5, num_words=10):
    print(f"â–¶ {title} ë°ì´í„° í† í”½ ë¶„ì„ ì¤‘...")

    df = pd.read_csv(file_path)
    df = df.dropna(subset=['clean_text'])

    # í† í°í™”
    tokenized_docs = df['clean_text'].apply(tokenize).tolist()

    # ë‹¨ì–´ ì‚¬ì „ & ì½”í¼ìŠ¤ ìƒì„±
    dictionary = corpora.Dictionary(tokenized_docs)
    corpus = [dictionary.doc2bow(text) for text in tokenized_docs]

    # LDA ëª¨ë¸ í•™ìŠµ
    lda_model = models.LdaModel(
        corpus,
        num_topics=num_topics,
        id2word=dictionary,
        passes=10,
        random_state=42
    )

    # í† í”½ë³„ ë‹¨ì–´ ì¶œë ¥
    topics = lda_model.print_topics(num_words=num_words)
    print(f"\nğŸ“˜ [{title}] í† í”½ë³„ ì£¼ìš” ë‹¨ì–´\n")
    for i, topic in enumerate(topics):
        print(f" í† í”½ {i+1}: {topic[1]}")

    # ----------  WordCloud ì‹œê°í™” ----------
    for i in range(num_topics):
        plt.figure(figsize=(6, 6))
        topic_words = dict(lda_model.show_topic(i, topn=30))
        wc = WordCloud(
            font_path=font_path,  #  ìë™ ì„¤ì •ëœ í°íŠ¸ ì‚¬ìš©
            background_color='white',
            colormap='tab10',
            width=800, height=800
        ).generate_from_frequencies(topic_words)
        plt.imshow(wc, interpolation='bilinear')
        plt.axis('off')
        plt.title(f"{title} - í† í”½ {i+1}", fontsize=14)
        plt.tight_layout()
        plt.savefig(f"../datas/{title}_topic{i+1}.png", dpi=300)
        plt.close()  # ğŸ”¹ ë©”ëª¨ë¦¬ ì ˆì•½

    # CSV ì €ì¥
    topic_data = []
    for i, topic in enumerate(topics):
        words = [w.split('*')[1].replace('"', '').strip() for w in topic[1].split('+')]
        topic_data.append({'ì‹œê¸°': title, 'í† í”½': f'Topic {i+1}', 'ë‹¨ì–´': ', '.join(words)})

    pd.DataFrame(topic_data).to_csv(f"../datas/{title}_topics.csv", index=False, encoding='utf-8-sig')
    print(f" ì™„ë£Œ: {title} ({num_topics}ê°œ í† í”½ ì €ì¥ë¨)\n")

# ------------------------------------------------------------
# ğŸ”¹ ì‹¤í–‰ êµ¬ê°„
# ------------------------------------------------------------
file_2015_2019 = "../datas/clean_2015_2019.csv"
file_2020_2025 = "../datas/clean_2020_2025.csv"

lda_topic_modeling(file_2015_2019, "2015â€“2019")
lda_topic_modeling(file_2020_2025, "2020â€“2025")